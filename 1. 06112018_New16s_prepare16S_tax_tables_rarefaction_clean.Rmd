---
title: "Filter 16S Taxa Tables"
author: "Sebastian Schmidt"
date: "2018-11-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Prepare Environment

Attach relevant packages

```{r}
library("Matrix", warn.conflicts=F, quietly=T)
library("ggplot2", warn.conflicts=F, quietly=T)
library("RColorBrewer", warn.conflicts=F, quietly=T)

# load both functions as well:

source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.alpha_diversity.R")

source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.rarefaction.R")

# instalar paquetes

source("http://bioconductor.org/biocLite.R")
#biocManager("CMA")

#BiocManager::install(c("CMA"))

library(CMA)
#BiocManager::install("Biobase")
library(Biobase)
#install.packages("randomForest")
library(randomForest)
#install.packages("glmnet")
library(glmnet)

library(penalized)


```

Set parameters.

```{r}
PARAM <- list()
PARAM$folder.R <- paste0(getwd(), "/")
PARAM$folder.base <- gsub("Rmd/", "", PARAM$folder.R)
PARAM$folder.data <- paste0(PARAM$folder.base, "data/")
PARAM$folder.metadata <- paste0(PARAM$folder.base, "metadata/")
PARAM$folder.parameters <- paste0(PARAM$folder.base, "parameters/")
PARAM$folder.results <- paste0(PARAM$folder.base, "results/")

#Set parameters to filter taxa tables
PARAM$min.size_sample <- 500
PARAM$min.prevalence_tax <- 5
```

## Load Raw Taxa Tables

Read ASV table.

```{r}
file.asv_table <- paste0(PARAM$folder.data, "all_samples.asv_table.tsv.gz")
tmp.asv <- as.matrix(read.delim(file.asv_table, sep="\t", header=T, row.names = 1))
dim(tmp.asv)

# OR:

# metadata:
load(file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_16sDatacomplete(N=779).RData") # keeps here 795 samples
#save(data.sample, file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_16sDatacomplete(N=779_correct).RData")

# otutables and data
load(file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_otudataASV(N=779).RData")
load(file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_otudataOPEN(N=779).RData")

load(file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_otutableASV(N=779).RData")
load(file="D:/EMBL_STAY/DATA/AllSequenced16sData/29102018_otutableOPEN(N=779).RData")

data.sample<-data.sample[data.sample$MMPCID %in% colnames(otu.table.OPEN),]

tmp.asv<-otu.table.ASV
#rownames(tmp.asv)<-tmp.asv$ASV_name
tmp.asv<-as.matrix(tmp.asv)
dim(tmp.asv)

tmp.otu<-otu.table.OPEN
#rownames(tmp.asv)<-tmp.asv$ASV_name
tmp.otu<-as.matrix(tmp.otu)
dim(tmp.otu)

```

Filter by sample sizes and minimum taxa prevalence.

```{r}
t.asv <- tmp.asv[rowSums(tmp.asv > 0) >= PARAM$min.prevalence_tax, colSums(tmp.asv) >= PARAM$min.size_sample]
dim(t.asv)
```

After applying these filters, we retain `r 100 * ncol(t.asv) / ncol(tmp.asv)`% of samples, `r 100 * nrow(t.asv) / nrow(tmp.asv)`% of ASVs and `r 100 * sum(t.asv)/sum(tmp.asv)`% of total reads. Indeed, the removed samples contained just `r 100 * sum(tmp.asv[, colSums(tmp.asv) < PARAM$min.size_sample]) / sum(tmp.asv)`% of total reads.

Get sample sizes, re-scale (by removing samples that retain <80% of the previously set minimum size) and normalise by total sums.

```{r}
tmp.size <- colSums(t.asv)
t.asv <- t.asv[, tmp.size >= 0.8*PARAM$min.size_sample]
size.asv <- colSums(t.asv)
t.asv.rel <- t(t(t.asv) / size.asv)
dim(t.asv)
```

Repeat for open-reference 98% OTU table.

```{r}
file.otu_table <- paste0(PARAM$folder.data, "all_samples.open_ref.otu_table.tsv.gz")
tmp.otu <- as.matrix(read.delim(file.otu_table, sep="\t", header=T, row.names = 1))
dim(tmp.otu)

# already loaded, so not needed

```


```{r}
#First round of filtering.
t.otu <- tmp.otu[rowSums(tmp.otu > 0) >= PARAM$min.prevalence_tax, colSums(tmp.otu) >= PARAM$min.size_sample]
dim(t.otu)
```

```{r}
#Second round of filtering
tmp.size <- colSums(t.otu)
t.otu <- t.otu[, tmp.size >= 0.8*PARAM$min.size_sample]
size.otu <- colSums(t.otu)
t.otu.rel <- t(t(t.otu) / size.otu)
dim(t.otu)
```

After applying these filters, we retain `r 100 * ncol(t.otu) / ncol(tmp.otu)`% of samples, `r 100 * nrow(t.otu) / nrow(tmp.otu)`% of OTUs and `r 100 * sum(t.otu)/sum(tmp.otu)`% of total reads. Indeed, the removed samples contained just `r 100 * sum(tmp.otu[, colSums(tmp.otu) < PARAM$min.size_sample]) / sum(tmp.otu)`% of total reads.

# Perform rarefaction curves:

```{r}

################################################################################
#Toolbox 16S
#
#Convenience functions to perform rarefaction analyses
#
#2017-09-15
#sebastian.schmidt@embl.de
################################################################################

################################################################################
################################################################################
#Function: rarefaction_analysis
#
#Input: count table, (relative) rarefaction steps, iterations per step (optional), Hill q to perform
#The function accepts three input variables:
#  - count.table (a matrix, taxa are rows, needs to be provided)
#  - steps (relative rarefaction steps to use, with a default)
#  - iterations (number of iterations per step, default=100)
################################################################################

count.table<-as.matrix(t.asv) # for ASV data

count.table<-as.matrix(t.otu) # for OPEN OTU data
dim(count.table)

#source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.rarefaction.R")

#source("https://raw.githubusercontent.com/defleury/Toolbox_16S/master/R/function.alpha_diversity.R")


# Rarefy the dataset
raref.res<-rarefaction(count.table, steps=c(seq(0.01, 0.09, by=0.01), seq(0.1, 0.9, by=0.1), 0.99), iterations=100) # this is my output!!!!

# ALTERNATIVELY, this is the functions code, in case you want to run it step by step:
rarefaction <- function(count.table, steps=c(seq(0.01, 0.09, by=0.01), seq(0.1, 0.9, by=0.1), 0.99), iterations=100) {
  #Get current sample sizes
  size.sample <- colSums(count.table) # n of reads across the samples
  #Get overall taxa count
  n.tax <- nrow(count.table) # total taxa (3360 in the current case)
  
  #Get relative counts
  count.table <- as.matrix(count.table)
  ct.rel <- as.matrix(t(t(count.table) / size.sample)) # taxa by number of reads
  
  #Preallocate results collector data.frame
  #=> add trivial rarefaction step at 0 counts
  results.rarefy <- data.frame(
    sample.name = colnames(count.table),
    N.seq = 0,
    N.obs = 0
  )
  
  #Iterate through rarefaction steps and perform rarefactions
for (step in steps) {
    curr.sizes <- ceiling(size.sample * step)
    curr.N_obs <- mapply(function(rel.counts, n.rare, n.tax) {
      tmp.counts <- replicate(iterations, sample(1:n.tax, size = n.rare, prob = rel.counts, replace = T))
      mean(apply(tmp.counts, 2, function(x) {length(unique(x))}))
    }, rel.counts=as.data.frame(ct.rel), n.rare=curr.sizes, MoreArgs = list(n.tax=n.tax))
    
    for (s in 1:length(curr.sizes)) {
      rel.counts = ct.rel[,s]
      n.rare = curr.sizes[s]
      tmp.counts <- replicate(iterations, sample(1:n.tax, size = n.rare, prob = rel.counts, replace = T))
      tmp[s] = mean(apply(tmp.counts, 2, function(x) {length(unique(x))}))
    }
    #Append
    results.rarefy <- rbind(results.rarefy, data.frame(
      sample.name = colnames(count.table),
      N.seq = curr.sizes,
      N.obs = curr.N_obs
    ))
  }
  
  #Return
  results.rarefy # has sample name, n seq and n of observations for the  samples included in the analysis, whereas raref has the results for the total number of samplings performed
}

## --------------------------------------------------------------------##
### Calculate ALPHA-DIVERSITY; take the last line code only!!
# Hill diversity the dataset

D.rarefied <- function(count.table, size=1000, iterations=100, q.H=c(0, 1, 2)) # this is diversity for all samples at 1,000 reads for the a-diversity comparisons

  # calculate here richness (hill numbers; q=0), inv.Shannon (hill numbers; q=1) and Shannon (hill numbers q=2)
  
# ALTERNATIVELY, this is the functions code, in case you want to run it step by step:
Hill_Diversity.rarefied <- function(count.table, size=1000, iterations=100, q.H=c(0, 1, 2)) {
  #Get current sample sizes
  # this is to get the diversity from 1000 samples
  size.sample <- colSums(count.table)
  #Get overall taxa count
  n.tax <- nrow(count.table)
  
  #Get relative counts
  count.table <- as.matrix(count.table)
  ct.rel <- as.matrix(t(t(count.table) / size.sample))
  
  #Preallocate
  D.rarefied <- as.data.frame(matrix(nrow=length(size.sample), ncol=4))
  colnames(D.rarefied) <- c("sample.name", paste0("q.", q.H))
  D.rarefied[, "sample.name"] <- names(size.sample)
  
  #Iteratively generate count tables
  curr.ct <- apply(ct.rel, 2, function(p.vec) {replicate(iterations, table(sample(1:n.tax, size=size, prob=p.vec, replace=T)) / size)})
  #Iterate through q values and calculate rarefied diversities
  for (q.i in q.H) {
    #Handle special cases of q=0 (richness only) and q=1 (exp(Shannon))
    if (q.i == 0) {
      curr.D <- sapply(curr.ct, function(x) {mean(sapply(x, length))})
    } else if (q.i == 1) {
      curr.D <- sapply(curr.ct, function(x) {mean(sapply(x, function(vec) {exp(shannon(vec))}))})
    } else {
      curr.D <- sapply(curr.ct, function(x) {mean(sapply(x, function(vec) {sum(vec ^ q.i) ^ (1/(1-q.i))}))})
    }
    #Replace values for undersampled samples with NA
    curr.D[size.sample < size] <- NA
    #Store in results frame
    D.rarefied[, which(q.H == q.i)+1] <- curr.D
  }
  
#  D.rarefied
#}

div.rarefied = Hill_Diversity.rarefied(count.table, size=1000, iterations=100, q.H=c(0, 1, 2)) # only valid line code || the previous lines are not needed.

div.rarefied.asv<-div.rarefied # for ASV
div.rarefied.otu<-div.rarefied # for OPEN OTU


save(div.rarefied.asv, file="D:/EMBL_STAY/DATA/AllSequenced16sData/06112018_ASV_diversity.RData")

save(div.rarefied.otu, file="D:/EMBL_STAY/DATA/AllSequenced16sData/06112018_OTU_diversity.RData")

```

# Rarefaction plots

```{r}

data.rarefaction = raref.res
curr.plot <- ggplot(data.rarefaction, aes(x=N.seq, y=N.obs)) +
  geom_line(alpha=0.4, aes(group=sample.name)) +
  xlab("Number of Sequences Sampled") +
  ylab("Number of Taxa") +
  #facet_wrap(~ experiment, ncol=2) 
  theme_bw()
curr.plot
ggsave(curr.plot, filename=paste0("D:/EMBL_STAY/NEW 16s RUN/rarefaction_curves_overall_ASV.pdf"), width = 10, height=5)
ggsave(curr.plot, filename=paste0("D:/EMBL_STAY/NEW 16s RUN/rarefaction_curves_overall_ASV.png"), width = 10, height=5)

# by site (oral vs stool samples)

#data.rarefaction <- rarefaction(ot, steps=PARAM$rarefaction.levels, iterations=PARAM$rarefaction.iterations)
data.rarefaction = raref.res
#data.rarefaction$experiment <- data.sample[data.rarefaction$sample.name, "experiment"]
# to do this, you will need to add to raref.res a variable accounting for site
data.rarefaction$site<-substr(data.rarefaction$sample.na,13,14)
curr.plot <- ggplot(data.rarefaction, aes(x=N.seq, y=N.obs)) +
  geom_line(alpha=0.4, aes(group=sample.name)) +
  xlab("Number of Sequences Sampled") +
  ylab("Number of Taxa") +
  facet_wrap(~ site, ncol=2) +
  theme_bw()
curr.plot
figs_path <- "C:/Users/memolina/Documents/EMBL_STAY/16SLabResults"
ggsave(curr.plot, filename=paste0("D:/EMBL_STAY/NEW 16s RUN/rarefaction_curves_bySite_ASV.pdf"), width = 10, height=5)
ggsave(curr.plot, filename=paste0("D:/EMBL_STAY/NEW 16s RUN/rarefaction_curves_bySite_ASV.png"), width = 10, height=5)

```

# samples giving trouble:
div.rarefied[div.rarefied$q.2>1000 & !is.na(div.rarefied$q.2),]

       sample.name q.0 q.1       q.2
51  MMPC17945462OR   1   1  3603.835
252 MMPC46842363OR   1   1  1612.714
293 MMPC52426076OR   1   1  8921.641
312 MMPC55182682OR   1   1  8815.712
315 MMPC55275792OR   1   1 12261.441
346 MMPC60219438OR   1   1  5999.591
388 MMPC67100379OR   1   1  6788.592
473 MMPC80521134OR   1   1  7120.831
493 MMPC82991304OR   1   1  7521.384
538 MMPC89717189OR   1   1  2339.984
575 MMPC94657810OR   1   1  1904.294
594 MMPC97687292OR   1   1 13443.452

       sample.name q.0 q.1       q.2
51  MMPC17945462OR   1   1  3618.030
252 MMPC46842363OR   1   1  1651.535
293 MMPC52426076OR   1   1 11176.371
312 MMPC55182682OR   1   1  8289.278
315 MMPC55275792OR   1   1 10728.620
346 MMPC60219438OR   1   1  6251.819
388 MMPC67100379OR   1   1  6058.109
473 MMPC80521134OR   1   1  6903.054
493 MMPC82991304OR   1   1  9614.105
538 MMPC89717189OR   1   1  2103.322
575 MMPC94657810OR   1   1  2059.848
601 MMPC98504055OR   1   1  8742.416

       sample.name q.0 q.1       q.2
51  MMPC17945462OR   1   1  4019.902
252 MMPC46842363OR   1   1  1845.691
293 MMPC52426076OR   1   1 10204.754
346 MMPC60219438OR   1   1  7153.272
376 MMPC65312583OR   1   1 19532.650
473 MMPC80521134OR   1   1  7937.088
493 MMPC82991304OR   1   1  8853.625
538 MMPC89717189OR   1   1  2180.794
575 MMPC94657810OR   1   1  2207.102

       sample.name q.0 q.1       q.2
51  MMPC17945462OR   1   1  3758.584
93  MMPC25677890ST   1   1 12697.994
252 MMPC46842363OR   1   1  1955.500
312 MMPC55182682OR   1   1  8860.573
346 MMPC60219438OR   1   1  6223.168
376 MMPC65312583OR   1   1 19205.076
388 MMPC67100379OR   1   1  7194.934
473 MMPC80521134OR   1   1 11019.043
493 MMPC82991304OR   1   1  7526.051
538 MMPC89717189OR   1   1  2014.836
575 MMPC94657810OR   1   1  1986.392
601 MMPC98504055OR   1   1 10597.738

